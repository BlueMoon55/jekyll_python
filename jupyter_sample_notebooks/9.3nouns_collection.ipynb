{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文章を入力\n",
      "クイックリスト掲載案件の相談対応手順\n",
      "[['クイック', '名詞,一般,*,*'],\n",
      " ['リスト', '名詞,一般,*,*'],\n",
      " ['掲載', '名詞,サ変接続,*,*'],\n",
      " ['案件', '名詞,一般,*,*'],\n",
      " ['の', '助詞,連体化,*,*'],\n",
      " ['相談', '名詞,サ変接続,*,*'],\n",
      " ['対応', '名詞,サ変接続,*,*'],\n",
      " ['手順', '名詞,一般,*,*']]\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer # janome.tokenizerをインポート\n",
    "import re, pprint                      # reとpprintモジュールをインポート\n",
    "\n",
    "''' 形態素解析を行う\n",
    "    text   :解析対象の文章\n",
    "    戻り値 :見出しと品詞のペアを格納した多重リスト\n",
    "'''    \n",
    "def analyze(text):                  # ①\n",
    "    t = Tokenizer()                 # Tokenizerオブジェクトを生成\n",
    "    tokens = t.tokenize(text)       # 形態素解析を実行\n",
    "    result = []                     # ②形態素と品詞を格納するリスト\n",
    "    \n",
    "    for token in tokens:            # ③リストからTokenオブジェクトを1つずつ取り出す\n",
    "        result.append(              # 形態素と品詞情報をリストにしてresultに追加\n",
    "            [token.surface,         # 形態素を取得\n",
    "             token.part_of_speech]) # 品詞情報を取得\n",
    "    return(result)                  # 解析結果の多重リストを返す\n",
    "\n",
    "\n",
    "#=================================================\n",
    "# プログラムの起点\n",
    "#=================================================\n",
    "if __name__  == '__main__':\n",
    "\n",
    "    print('文章を入力')\n",
    "    input = input()                  # 文章を取得\n",
    "    pprint.pprint(analyze(input))    # 入力された文章を解析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dictionary.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6c5e19bcf384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m  \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# 辞書ファイルを読み込んで登録済みの名詞のリストを取得\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mn_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dictionary.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'文章を入力'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6c5e19bcf384>\u001b[0m in \u001b[0;36mread_dictionary\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m                  \u001b[1;31m# ファイルを指定\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m                        \u001b[1;31m# 読み出し専用で開く\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf_8'\u001b[0m          \u001b[1;31m# エンコード方式を指定\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         )    \n\u001b[0;32m     20\u001b[0m     \u001b[0mp_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# 1行ずつ読み込んでリストの要素にする\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dictionary.txt'"
     ]
    }
   ],
   "source": [
    "from analyzer import *              # analyzerモジュールをインポート\n",
    "\n",
    "file_name = ''                      # 辞書ファイル名を保持する変数\n",
    "\n",
    "'''\n",
    "辞書ファイルから名詞データを読み込む関数\n",
    "    file   : 辞書ファイル名\n",
    "    戻り値 : 辞書ファイルから抽出した名詞のリスト\n",
    "\n",
    "'''\n",
    "def read_dictionary(file):\n",
    "    global file_name                # グローバル変数file_name\n",
    "    file_name = file                # ファイル名をfile_nameに代入\n",
    "    noun_lst = []                   # 辞書ファイルの名詞を保持するリスト\n",
    "    pfile = open(                   # ファイルオープン\n",
    "        file_name,                  # ファイルを指定\n",
    "        'r',                        # 読み出し専用で開く\n",
    "        encoding = 'utf_8'          # エンコード方式を指定\n",
    "        )    \n",
    "    p_lines = pfile.readlines()     # 1行ずつ読み込んでリストの要素にする\n",
    "    pfile.close()                   # ファルクローズ\n",
    "    \n",
    "    for line in p_lines:            # p_linesから1行データを取り出す\n",
    "        str = line.rstrip('\\n')     # 1行のデータの末尾から改行文字を取り除く\n",
    "        if (str!=''):               # 1行のデータが空文字ではない場合\n",
    "            noun_lst.append(str)    # noun_lstに追加する\n",
    "\n",
    "    return noun_lst                 # ファイルから抽出した名詞のリストを返す\n",
    "\n",
    "'''\n",
    "noun_lstの要素をまるごと辞書に書き込む関数\n",
    "    noun_lst : 登録済みの名詞と新たに登録する名詞のリスト\n",
    "\n",
    "'''\n",
    "def save(noun_lst):\n",
    "    nouns = []                      # 辞書ファイルに書き込むデータを保持するリスト\n",
    "    for noun in noun_lst:           # noun_lstから名詞データを1つずつ取り出す\n",
    "        nouns.append(noun + '\\n')   # 末尾に改行を付加してnounsに追加する\n",
    "\n",
    "    with open(                      # 辞書ファイルに書き込む\n",
    "        file_name,                  # 辞書ファイルを指定\n",
    "         'w',                       # 書き換えモードで開く\n",
    "         encoding = 'utf_8'         # エンコード方式を指定\n",
    "         ) as f:                    # イテレート可能なファイルオブジェクトとして取得する\n",
    "        f.writelines(nouns)         # nounsの1行の名詞データをすべてファイルに書き込む\n",
    "\n",
    "'''\n",
    "名詞を学習する関数\n",
    "    parts    : 形態素解析の結果のリスト\n",
    "    noun_lst : 登録済みの名詞のリスト\n",
    "'''\n",
    "def study_noun(parts, noun_lst):    \n",
    "    for word, part in parts:          # 多重リストの要素を2つのパラメーターに取り出す    \n",
    "        if (keyword_check(part)):     # keyword_check()関数の戻り値がTrueの場合\n",
    "            isNew = True              # フラグを立てておく           \n",
    "            for element in noun_lst:  # リストnoun_lstを反復処理\n",
    "                if(element == word):  # インプットされた名詞が既存の名詞とマッチする\n",
    "                    isNew = False     # isNewをFalseにする\n",
    "                    break             # ループを止める\n",
    "            if isNew:                 # isNewがTrueである\n",
    "                noun_lst.append(word) # リストnoun_lstに存在しない名詞なので追加する\n",
    "    save(noun_lst)                    # save()でnoun_lstを辞書ファイルに書き込む\n",
    "\n",
    "    \n",
    "#=================================================\n",
    "# プログラムの起点\n",
    "#=================================================\n",
    "if __name__  == '__main__':\n",
    "    # 辞書ファイルを読み込んで登録済みの名詞のリストを取得\n",
    "    n_lst = read_dictionary('dictionary.txt')\n",
    "\n",
    "    print('文章を入力')\n",
    "    # 文章を取得\n",
    "    input = input()\n",
    "    # 入力された文章を解析\n",
    "    result = analyze(input)            \n",
    "    # 解析結果と登録済みの名詞のリストをを引数にして学習関数を呼ぶ\n",
    "    study_noun(result, n_lst)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
